{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8odUU-xR7pX"
   },
   "source": [
    "# CAMP II Surgical Workflow Analysis Exercise\n",
    "\n",
    "It is highly recommended to complete the CAMP II Exercises on Classification before this one!  \n",
    "Make sure to activate the GPU in colab before you start this exercise.\n",
    "\n",
    "In this exercise, we will segment the liver, using as ground truth annotation provided in the datase. \n",
    "\n",
    "This notebook has many codeblocks already in place to help you get started. Places where you have to add your own code are clearly marked with \"TASK\" and lines (\"-----\"). When a variable you have to implement is used later on, we placed a name and description in the task bracket (see example below). These markings are only there to guide you toward what you have to implement to complete the exercise, feel free to experiment beyond them.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FtmaZtv80_Fy"
   },
   "outputs": [],
   "source": [
    "# TASK: description of the task you need to do ---------------------------------\n",
    "# my_variable_name: a variable that is used later on, so the name should be right\n",
    "\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHA4qbbhIVx_"
   },
   "source": [
    "Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3oVWssdTq1U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scvi-tools 0.16.0 requires pytorch-lightning<1.6,>=1.5, but you have pytorch-lightning 1.6.2 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -qq install pytorch_lightning==1.6.2\n",
    "!pip -qq install -U segmentation-models-pytorch\n",
    "!pip -qq install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB2_3JsPRsS-"
   },
   "source": [
    "Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xffk_kwIfpII"
   },
   "outputs": [],
   "source": [
    "# If you get an error here about access being denied - just try again until it works\n",
    "!gdown --id 1MHp64mCt2m8NxCW3-4kjD39m3Rry0ekA\n",
    "!unzip -qq liver_endoscopy_dataset\n",
    "!rm liver_endoscopy_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ha3HUhNmIRdu"
   },
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xuKXhrOwUUfP"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "from re import T\n",
    "import segmentation_models_pytorch as pytorch_models\n",
    "from skimage.color import label2rgb\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from typing import Optional\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrCvA5B-T2vz"
   },
   "source": [
    "## 0. Dataset\n",
    "The LiverEndoscopy class processes the dataset so that it can be used for our segementation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LggGPL2ZSDpQ"
   },
   "outputs": [],
   "source": [
    "video_splits = {'train': ['01', '09', '17', '20', '25', '27', '28', '35', '37', '43', '55'], 'val': ['12', '24', '26'], 'test': ['18', '48', '52']}\n",
    "\n",
    "\n",
    "class LiverEndoscopy(Dataset):\n",
    "    def __init__(self,\n",
    "                 task_type: str = 'classification', split: str = 'train', balance_data: bool = False, temporal: bool = False,\n",
    "                 pil_transform: Optional[transforms.Compose] = None, tensor_transform: Optional[transforms.Compose] = None):\n",
    "        assert split in ['train', 'val', 'test']\n",
    "        self.split = split\n",
    "        self.balance_data = balance_data\n",
    "        self.task_type = task_type\n",
    "        self.temporal = temporal\n",
    "        self.pil_transform = pil_transform\n",
    "        self.tensor_transform = tensor_transform\n",
    "\n",
    "        export_dataset_path = Path('data')\n",
    "        self.images_path = export_dataset_path / 'images'\n",
    "        self.seg_masks_path = export_dataset_path / 'seg_masks'\n",
    "        with open(export_dataset_path / 'classification_annotations.json', 'r') as f:\n",
    "            self.classification_annotations = json.load(f)\n",
    "        with open(export_dataset_path / 'phase_annotations.json', 'r') as f:\n",
    "            self.workflow_phase_annotations = json.load(f)\n",
    "        with open(export_dataset_path / 'has_liver.json', 'r') as f:\n",
    "            self.has_liver = json.load(f)\n",
    "\n",
    "        if task_type == 'classification' or task_type == 'segmentation' or (task_type == 'workflow' and not temporal):\n",
    "            self.image_names = []\n",
    "            for image_path in sorted(self.images_path.glob('*.png')):\n",
    "                video_id = image_path.name.split('_')[0].replace('video', '')\n",
    "                if video_id in video_splits[split]:\n",
    "                    self.image_names.append(image_path.name.replace('.png', ''))\n",
    "            self.image_names = sorted(self.image_names)\n",
    "\n",
    "        if balance_data:\n",
    "            self.do_balance_data(task_type, temporal)\n",
    "\n",
    "    def do_balance_data(self, task_type, temporal):\n",
    "        print('Balancing data by oversampling under-represented classes...')\n",
    "        class_to_samples = defaultdict(list)\n",
    "        if not temporal:\n",
    "            for image_name in self.image_names:\n",
    "                if task_type == 'segmentation':\n",
    "                    label = self.has_liver[image_name]\n",
    "                class_to_samples[label].append(image_name)\n",
    "            max_number = max([len(elem) for elem in class_to_samples.values()])\n",
    "            self.image_names = []\n",
    "            for key, value in class_to_samples.items():\n",
    "                if len(value) < max_number:\n",
    "                    self.image_names += random.choices(value, k=max_number)\n",
    "                else:\n",
    "                    self.image_names += value\n",
    "            random.shuffle(self.image_names)\n",
    "        else:\n",
    "            for video_id, window in self.windows:\n",
    "                label = self.workflow_phase_annotations[f'video{video_id}_{str(window[-1]).zfill(6)}']\n",
    "                class_to_samples[label].append((video_id, window))\n",
    "            max_number = max([len(elem) for elem in class_to_samples.values()])\n",
    "            self.windows = []\n",
    "            for key, value in class_to_samples.items():\n",
    "                if len(value) < max_number:\n",
    "                    self.windows += random.choices(value, k=max_number)\n",
    "                else:\n",
    "                    self.windows += value\n",
    "            random.shuffle(self.windows)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image_path = self.images_path / f'{image_name}.png'\n",
    "        seg_mask_path = self.seg_masks_path / f'{image_name}_liver_mask.png'\n",
    "        image = Image.open(image_path)\n",
    "        if self.pil_transform is not None:\n",
    "            image = self.pil_transform(image)\n",
    "        image_tensor = transforms.ToTensor()(image)\n",
    "        if self.tensor_transform is not None:\n",
    "            image_tensor = self.tensor_transform(image_tensor)\n",
    "        seg_mask = Image.open(seg_mask_path)\n",
    "        if self.pil_transform is not None:\n",
    "            seg_mask = self.pil_transform(seg_mask)\n",
    "        seg_mask_tensor = transforms.ToTensor()(seg_mask)[0].float()\n",
    "        if self.tensor_transform is not None:\n",
    "            seg_mask_tensor = self.tensor_transform(seg_mask_tensor)\n",
    "        intrument_exists = int(self.classification_annotations[image_name])\n",
    "\n",
    "        if self.task_type == 'segmentation':\n",
    "            return image_tensor, seg_mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl8Ux9y6UUaY"
   },
   "source": [
    "## A. Segmentation of the liver in cholec80 dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeometry.losses import DiceLoss\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def l1_loss(ground_truth, prediction):\n",
    "    # TASK: compute the L1 loss ---------------------------------------------------------------\n",
    "    l1 = torch.nn.L1Loss()\n",
    "    loss = l1(ground_truth, prediction)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    return loss\n",
    "\n",
    "def dice_loss(ground_truth, prediction):\n",
    "    # TASK: compute the dice loss --------------------------------------------------------------\n",
    "    dice = DiceLoss()\n",
    "    loss = dice(ground_truth, prediction)\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    return loss\n",
    "\n",
    "def dice_score(ground_truth, prediction):\n",
    "  # TASK: compute the dice score -------------------------------------------------------------\n",
    "  score = distance.dice(ground_truth, prediction)\n",
    "  # -----------------------------------------------------------------------------------------\n",
    "  return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EGMmRo-yZk5"
   },
   "source": [
    "### A.1 Network\n",
    "Here we define the network, including it's behaviour during training and validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RNKx8bgUUQLY"
   },
   "outputs": [],
   "source": [
    "class LiverSegmentation(pl.LightningModule):\n",
    "    def __init__(self, model,lr,loss):\n",
    "        super().__init__()\n",
    "        self.backbone = model\n",
    "        self.lr = lr\n",
    "        self.loss = loss\n",
    "        self.metric = dice_score\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x)\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y = y.unsqueeze(dim=1)\n",
    "        # TASK: perform the forward pass, compute the loss and the metric of each step --------------\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "        metric = self.metric(y, y_pred)\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        return {\"loss\": loss, \"metric\": metric}\n",
    "\n",
    "    def training_epoch_end(self,output):\n",
    "        loss = 0\n",
    "        metric = 0\n",
    "        for o in output:\n",
    "            # TASK: compute the loss and metric of the epoch -------------------------------------------\n",
    "            loss = loss + o[\"loss\"]\n",
    "            metric = metric + o[\"metric\"]\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "        loss = loss / len(output)\n",
    "        metric = metric / len(output)\n",
    "        self.writer.add_scalar('Epoch_loss/training', loss, self.current_epoch)\n",
    "        self.writer.add_scalar('Epoch_metric/training', metric, self.current_epoch)\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y = y.unsqueeze(dim=1)\n",
    "        # TASK: perform the forward pass, compute the loss and the metric of each step --------------\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "        metric = self.metric(y, y_pred)\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        y_pred_plot = np.array(y_pred.cpu(), dtype=float)\n",
    "        image = self.prepare_visualization(y[0, 0, :, :].cpu().numpy(), y_pred_plot[0, 0, :, :], x[0, 0, :, :].cpu().numpy())\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=4)\n",
    "        ax[0].imshow(x[0, 0, :, :].cpu(),cmap=\"gray\")\n",
    "        ax[0].set_title('Image')\n",
    "        ax[1].imshow(y[0, 0, :, :].cpu().numpy().astype(\"uint8\"), cmap=\"gray\")\n",
    "        ax[1].set_title('GT Segm')\n",
    "        ax[2].imshow(y_pred_plot[0, 0, :, :], cmap=\"gray\")\n",
    "        ax[2].set_title('Pred Segm')\n",
    "        ax[3].imshow(image)\n",
    "        ax[3].set_title('Overlay')\n",
    "        self.writer.add_figure(\"Validation/\"+str(batch_idx), fig, self.current_epoch)\n",
    "        plt.close()\n",
    "        return {\"loss\": loss, \"metric\": metric}\n",
    "\n",
    "    def prepare_visualization(self,y,y_pred,image):\n",
    "        annotation_pred = (y_pred>0.5).astype(\"uint8\") # It will evaluate the logical expression y_predict>0.25 and return True or False \n",
    "        annotation_pred = np.uint8(annotation_pred)\n",
    "        annotation_gt= np.uint8(y)\n",
    "\n",
    "        overlay = np.copy(image) \n",
    "        image_label_overlay = label2rgb(annotation_pred, image=overlay, bg_label=0, alpha=0.5, colors=[\"red\"])    \n",
    "\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "        redImg = np.zeros(image.shape, image.dtype)\n",
    "        redImg[:,:] = (0, 255, 0)\n",
    "        redMask = cv2.bitwise_and(redImg, redImg, mask=annotation_gt)\n",
    "        image_mask1 = np.float32(image_label_overlay)\n",
    "        image = cv2.addWeighted(redMask, 0.05, image_mask1, 0.95,0.0)\n",
    "        return image\n",
    "\n",
    "\n",
    "    def validation_epoch_end(self,output):\n",
    "        loss = 0\n",
    "        metric = 0\n",
    "        for o in output:\n",
    "            loss = loss + o[\"loss\"]\n",
    "            metric = metric + o[\"metric\"]\n",
    "\n",
    "          # TASK: compute the loss and metric of the epoch -------------------------------------------\n",
    "          # metric\n",
    "          # loss\n",
    "          # ------------------------------------------------------------------------------------------\n",
    "        loss = loss / len(output)\n",
    "        metric = metric / len(output)\n",
    "        self.log('val_dice', metric)\n",
    "        self.writer.add_scalar('Epoch_loss/validation', loss, self.current_epoch)\n",
    "        self.writer.add_scalar('Epoch_metric/validation', metric, self.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3SDGjKrUQxA"
   },
   "source": [
    "### A.2 Models\n",
    "Here we define 4 different NN models. We will compare them and find the one that is best performing for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R3fJcWkDUP-j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42) # Fix the seed\n",
    "\n",
    "unet3 = pytorch_models.Unet(\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    "    encoder_depth=3,                # Amount of down- and upsampling of the Unet\n",
    "    decoder_channels=(64, 32,16),   # Amount of channels\n",
    "    encoder_weights = None,         # Model does not download pretrained weights\n",
    "    activation = 'sigmoid'            # Activation function to apply after final convolution       \n",
    "    )\n",
    "\n",
    "\n",
    "unet5 = pytorch_models.Unet(\n",
    "    in_channels=3,                  \n",
    "    classes=1,                      \n",
    "    encoder_depth=5,                \n",
    "    decoder_channels=(256, 128, 64, 32, 16), \n",
    "    encoder_weights = None,\n",
    "    activation = 'sigmoid'                    \n",
    "    )\n",
    "\n",
    "\n",
    "unet7 = pytorch_models.Unet(\n",
    "    in_channels=3,                  \n",
    "    classes=1,                      \n",
    "    encoder_depth=7,                \n",
    "    decoder_channels=(1024, 512, 256, 128, 64, 32,16), \n",
    "    encoder_weights = None,\n",
    "    activation = 'sigmoid'                \n",
    "    )\n",
    "\n",
    "\n",
    "resnet34 = pytorch_models.Unet(\n",
    "    in_channels = 3,\n",
    "    classes=1,\n",
    "    encoder_name='resnet34', \n",
    "    encoder_depth=5, encoder_weights=None,\n",
    "    decoder_channels=(256, 128, 64, 32, 16),\n",
    "    activation = 'sigmoid'              \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3wg7rDsUROz"
   },
   "source": [
    "### A.3 Metrics & Losses\n",
    "Here we code the L1-loss the dice loss and the dice score functions. After that we test their implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Cq0lQEG7UQE7"
   },
   "outputs": [],
   "source": [
    "def l1_loss(ground_truth, prediction):\n",
    "    # TASK: compute the L1 loss ---------------------------------------------------------------\n",
    "    l1 = torch.nn.L1Loss()\n",
    "    loss = l1(ground_truth, prediction)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    return loss\n",
    "\n",
    "def dice_loss(ground_truth, prediction):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = prediction.view(-1)\n",
    "    tflat = ground_truth.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "def dice_score(ground_truth, prediction):\n",
    "    return -1 * dice_loss(ground_truth, prediction) + 1\n",
    "  # -----------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R5Te90m3Klz"
   },
   "source": [
    "Here we test the implementation of the losses and the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rH9aXyqg2vKm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing data by oversampling under-represented classes...\n",
      "Loss test 1 tensor(0.) tensor(0.)\n",
      "Loss test 2 tensor(0.) tensor(0.)\n",
      "Metric test 1 tensor(0.) ; Metric test 2 tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "pil_transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "train_dataset = LiverEndoscopy(split='train', balance_data=True, task_type='segmentation', temporal=False, pil_transform=pil_transform)\n",
    "x_0, y_0 = train_dataset[0]\n",
    "y_0 = y_0.unsqueeze(dim=1)\n",
    "\n",
    "x_1, y_1 = train_dataset[0]\n",
    "y_1 = y_1.unsqueeze(dim=1)\n",
    "\n",
    "print(\"Loss test 1\", l1_loss(y_0, y_0), dice_loss(y_0, y_0))\n",
    "print(\"Loss test 2\", l1_loss(y_0, y_1), dice_loss(y_0, y_1))\n",
    "print(\"Metric test 1\", dice_loss(y_0, y_0), \"; Metric test 2\", dice_loss(y_0, y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxx29DjVzbcL"
   },
   "source": [
    "### A.4 Training, finally!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ-2qzMpqBwE"
   },
   "source": [
    "Run this cell if you want to remove all the saved tensorboard logs (`runs`) and/or the checkpoints (`lightning_logs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hTbckB1GpaSE"
   },
   "outputs": [],
   "source": [
    "!rm -rf runs\n",
    "!rm -rf lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeAlArKJ3dzL"
   },
   "source": [
    "In this cell we will test different combinations of models, learning rates and losses. You will modify the line of code `net = LiverSegmentation(unet3, lr=0.002, loss=dice_loss)` by including different models (see above), learning rates in [0.1, 1e-5] and L1 or dice loss. You will also need to change `max_epochs` and evaluate its impact on the performance of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UHNg2KImrLkn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing data by oversampling under-represented classes...\n",
      "Balancing data by oversampling under-represented classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type | Params\n",
      "----------------------------------\n",
      "0 | backbone | Unet | 21.5 M\n",
      "----------------------------------\n",
      "21.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.5 M    Total params\n",
      "42.971    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/mostafa.shahhosseini/miniconda3/envs/mossi/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 112 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "/home/icb/mostafa.shahhosseini/miniconda3/envs/mossi/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 112 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c50418101f241d3bd3d4989c0a78951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42) # Fix the seed\n",
    "\n",
    "# Split the dataset in train and validation\n",
    "pil_transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "train_dataset = LiverEndoscopy(split='train', balance_data=True, task_type='segmentation', temporal=False, pil_transform=pil_transform)\n",
    "val_dataset = LiverEndoscopy(split='val', balance_data=True, task_type='segmentation', temporal=False, pil_transform=pil_transform)\n",
    "\n",
    "# Create the dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the network\n",
    "net = LiverSegmentation(unet3, lr=0.002, loss=dice_loss)\n",
    "\n",
    "# Define how and when to save your models during training\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_dice',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    every_n_epochs=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, \n",
    "                    precision=16, \n",
    "                    callbacks=checkpoint_callback,\n",
    "                    check_val_every_n_epoch=1,\n",
    "                    log_every_n_steps=5,\n",
    "                     max_epochs=10\n",
    "                     )\n",
    "\n",
    "# Train!\n",
    "trainer.fit(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YV1vNux1V_sF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 42124), started 0:19:27 ago. (Use '!kill 42124' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-48cd29c5ac0e1f71\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-48cd29c5ac0e1f71\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42) # Fix the seed\n",
    "\n",
    "# Split the dataset in train and validation\n",
    "pil_transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "train_dataset = LiverEndoscopy(split='train', balance_data=True, task_type='segmentation', temporal=False, pil_transform=pil_transform)\n",
    "val_dataset = LiverEndoscopy(split='val', balance_data=True, task_type='segmentation', temporal=False, pil_transform=pil_transform)\n",
    "\n",
    "# Create the dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the network\n",
    "net = LiverSegmentation(unet5, lr=0.002, loss=dice_loss)\n",
    "\n",
    "# Define how and when to save your models during training\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_dice',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    every_n_epochs=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, \n",
    "                    precision=16, \n",
    "                    callbacks=checkpoint_callback,\n",
    "                    check_val_every_n_epoch=1,\n",
    "                    log_every_n_steps=5,\n",
    "                     max_epochs=5\n",
    "                     )\n",
    "\n",
    "# Train!\n",
    "trainer.fit(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "F3SDGjKrUQxA",
    "K3wg7rDsUROz"
   ],
   "name": "Segmentation_CAMP2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
